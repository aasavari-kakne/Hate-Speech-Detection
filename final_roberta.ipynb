{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"nlu","language":"python","name":"nlu"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"final_roberta.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"aXYg4dZKUduZ","colab_type":"code","outputId":"296eaedb-972f-4347-fd7e-b0223451a326","executionInfo":{"status":"ok","timestamp":1591031271262,"user_tz":-330,"elapsed":5502,"user":{"displayName":"Aasavari Kakne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWQl8fvFsC3iDOy-6lJbBTvKY_wv0bI9-S3-CElg=s64","userId":"10718872132958724968"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","# some_file.py\n","%cd drive/My\\ Drive/CS224u_Final_Project\n","!pwd"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/CS224u_Final_Project\n","/content/drive/My Drive/CS224u_Final_Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wOe3Mq77waIP","colab_type":"code","outputId":"94228529-f2ba-4e25-8c18-11b1116aeabe","executionInfo":{"status":"ok","timestamp":1591031275235,"user_tz":-330,"elapsed":9463,"user":{"displayName":"Aasavari Kakne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWQl8fvFsC3iDOy-6lJbBTvKY_wv0bI9-S3-CElg=s64","userId":"10718872132958724968"}},"colab":{"base_uri":"https://localhost:8080/","height":326}},"source":["%load_ext autoreload\n","%autoreload 2\n","!pip3 install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.10.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"59PEDmdaT9ZR","colab_type":"code","colab":{}},"source":["import transformers\n","from transformers import RobertaModel, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup, RobertaConfig\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader\n","import os\n","from dataset_loader import COVID19TweetDataset\n","from final_classifier import FinalClassifier\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from torch.utils.tensorboard import SummaryWriter\n","from pathlib import Path\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZMobX_W7T9Zg","colab_type":"code","outputId":"247c7ac9-ddb4-41d0-c77a-ab2c42c38e6b","executionInfo":{"status":"ok","timestamp":1591031284882,"user_tz":-330,"elapsed":2920,"user":{"displayName":"Aasavari Kakne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWQl8fvFsC3iDOy-6lJbBTvKY_wv0bI9-S3-CElg=s64","userId":"10718872132958724968"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# TODO: Add tensorboard logging \n","writer = SummaryWriter()\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(\"Using Device: {}\".format(device))\n","# Creating dataset\n","DATA_DIR = './data'\n","dataset_path_train = os.path.join(DATA_DIR, 'train.tsv')\n","dataset_path_test = os.path.join(DATA_DIR, 'test.tsv')\n","dataset_path_val = os.path.join(DATA_DIR, 'val.tsv')\n","\n","tweets_train = pd.read_csv(dataset_path_train, sep='\\t')\n","tweets_test = pd.read_csv(dataset_path_test, sep='\\t')\n","tweets_val = pd.read_csv(dataset_path_val, sep='\\t')\n","\n","PRE_TRAINED_MODEL_NAME = 'roberta-base'\n","MAX_LEN = 200\n","BATCH_SIZE = 32\n","RANDOM_SEED = 42\n","\n","tokenizer = RobertaTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using Device: cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x9QLhjtXT9Zs","colab_type":"code","colab":{}},"source":["# Changing dataframes into dictionary of COVID19TweetDataset objects\n","def create_data_loader(data_set, tokenizer, max_len, batch_size):\n","    temp_data_set = COVID19TweetDataset(data_set['text.clean'].to_numpy(), data_set['expert'].to_numpy(),\n","                                    data_set['id'].to_numpy(), max_len, tokenizer)\n","\n","    return DataLoader(temp_data_set, batch_size=batch_size)\n","\n","# Creating data loaders\n","data_loader = {\n","                'train': create_data_loader(tweets_train, tokenizer, MAX_LEN, BATCH_SIZE),\n","                'val': create_data_loader(tweets_val, tokenizer, MAX_LEN, BATCH_SIZE),\n","                'test': create_data_loader(tweets_test, tokenizer, MAX_LEN, BATCH_SIZE)\n","            }\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nnERHjwKT9Z0","colab_type":"code","colab":{}},"source":["# Initializing model\n","roberta_config = RobertaConfig.from_pretrained(PRE_TRAINED_MODEL_NAME, output_hidden_states=True)\n","roberta_model = RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME, config=roberta_config)\n","\n","model = FinalClassifier(2, roberta_model)\n","model = model.to(device)\n","\n","NUM_EPOCHS = 20\n","optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps=0,\n","                                            num_training_steps=len(data_loader['train']) * NUM_EPOCHS)\n","\n","class_weights = torch.FloatTensor([1.0, 2.088]).cuda()\n","criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C_c7kGTXT9Z6","colab_type":"code","colab":{}},"source":["# Train loop\n","def train(num_epochs, model):\n","    history = []\n","    best_val_f1 = float('-inf')\n","    label_history = []\n","    tensorboard_time_train = 0\n","    tensorboard_time_val = 0\n","\n","    for epoch in range(num_epochs):\n","        # Training\n","        model.train()\n","        train_loss_arr = []\n","        train_predicted_labels = []\n","        train_actual_labels = []\n","        train_tweet_ids = []\n","\n","        for step, batch in enumerate(tqdm(data_loader['train'])):\n","            tensorboard_time_train += 1\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","            tweet_ids = batch['tweet_ids']\n","\n","            outputs = model(input_ids, attention_mask)\n","            _, predictions = torch.max(outputs, dim=1)\n","            loss = criterion(outputs, labels)\n","            train_actual_labels += list(labels.detach().cpu().view(-1).numpy())\n","            train_predicted_labels += list(predictions.detach().cpu().view(-1).numpy())\n","            train_tweet_ids += tweet_ids\n","            train_loss_arr.append(loss.item())\n","\n","            loss.backward()\n","            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            optimizer.step()\n","            scheduler.step()\n","            optimizer.zero_grad()\n","            if step % 10 == 0:\n","                print(f'Train Epoch = {epoch}, Step = {step}, Train Loss = {np.mean(train_loss_arr)}')\n","            \n","            writer.add_scalar('train_loss', np.mean(train_loss_arr), tensorboard_time_train)\n","\n","        train_f1_score = f1_score(np.array(train_actual_labels), np.array(train_predicted_labels))\n","        train_acc = np.sum(np.array(train_actual_labels) == np.array(train_predicted_labels)) / len(train_set)\n","        writer.add_scalar('train_f1_score', train_f1_score, epoch)\n","\n","        # Validation \n","        model.eval()\n","        val_loss_arr = []\n","        val_predicted_labels = []\n","        val_actual_labels = []\n","        val_tweet_ids = []\n","        with torch.no_grad():\n","            for step, batch in enumerate(tqdm(data_loader['val'])):\n","                tensorboard_time_val += 1\n","                input_ids = batch['input_ids'].to(device)\n","                attention_mask = batch['attention_mask'].to(device)\n","                labels = batch['labels'].to(device)\n","                tweet_ids = batch['tweet_ids']\n","\n","                outputs = model(input_ids, attention_mask)\n","                _, predictions = torch.max(outputs, dim=1)\n","                loss = criterion(outputs, labels)\n","                val_actual_labels += list(labels.detach().cpu().view(-1).numpy())\n","                val_predicted_labels += list(predictions.detach().cpu().view(-1).numpy())\n","                val_tweet_ids += tweet_ids\n","\n","                val_loss_arr.append(loss.item())\n","                if step % 10 == 0:\n","                    print(f'Val Epoch = {epoch}, Step = {step}, Val Loss = {np.mean(val_loss_arr)}')\n","                \n","                writer.add_scalar('val_loss', np.mean(val_loss_arr), tensorboard_time_val)\n","\n","            val_f1_score = f1_score(np.array(val_actual_labels), np.array(val_predicted_labels))\n","            val_acc = np.sum(np.array(val_actual_labels) == np.array(val_predicted_labels)) / len(val_set)\n","            writer.add_scalar('val_f1_score', val_f1_score, epoch)\n","        \n","        # If we get better validation f1, save the labels/tweet ids for error analysis\n","        if val_f1_score > best_val_f1:\n","            best_val_f1 = val_f1_score\n","            np.save(os.path.join(DATA_DIR, 'label_history.npy'), list(zip(val_actual_labels, \n","                                                            val_predicted_labels, val_tweet_ids)))\n","            save(model, epoch, optimizer, np.mean(val_loss_arr), model_prefix='roberta_linear_baseline_model_weighted_loss')\n","        \n","        print(f'Epoch {epoch}')\n","        print('-' * 20)\n","        print(f'Train Loss = {np.mean(train_loss_arr)}, F-1 Score = {train_f1_score}, Acc = {train_acc}')\n","        print(f'Val Loss = {np.mean(val_loss_arr)}, F-1 Score = {val_f1_score}, Acc = {val_acc}')\n","\n","        # Save history\n","        history.append([np.mean(train_loss_arr), np.mean(val_loss_arr), train_f1_score, val_f1_score])\n","        np.save(os.path.join(DATA_DIR, 'history.npy'), history)\n","        print(\"Best F-1 score on validation dataset is {}\".format(best_val_f1))\n","\n","\n","def save(model, epoch, optimizer, loss, model_prefix='model_', root='/content/drive/My Drive/CS224u_Final_Project/.model'):\n","    path = Path(root) / (model_prefix + '.ep%d' % epoch)\n","    if not path.parent.exists():\n","        path.parent.mkdir()\n","\n","    torch.save({'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(), 'loss': loss}, path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Sjarnp1T9Z_","colab_type":"code","outputId":"3fa4412f-35c3-4acd-b009-047aba89c54c","executionInfo":{"status":"error","timestamp":1591031642942,"user_tz":-330,"elapsed":329524,"user":{"displayName":"Aasavari Kakne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWQl8fvFsC3iDOy-6lJbBTvKY_wv0bI9-S3-CElg=s64","userId":"10718872132958724968"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Call Train/Val Loop\n","print(\"Begin Training!\")\n","train(NUM_EPOCHS, model)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/500 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Begin Training!\n"],"name":"stdout"},{"output_type":"stream","text":["/content/drive/My Drive/CS224u_Final_Project/final_classifier.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  out = self.softmax(out)                          # BATCH_SIZE x 2\n","  0%|          | 1/500 [00:00<08:10,  1.02it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 0, Train Loss = 0.6860438585281372\n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 11/500 [00:07<05:28,  1.49it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 10, Train Loss = 0.6961346214467828\n"],"name":"stdout"},{"output_type":"stream","text":["  4%|▍         | 21/500 [00:14<05:17,  1.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 20, Train Loss = 0.6641499201456705\n"],"name":"stdout"},{"output_type":"stream","text":["  6%|▌         | 31/500 [00:20<05:12,  1.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 30, Train Loss = 0.6279888979850277\n"],"name":"stdout"},{"output_type":"stream","text":["  8%|▊         | 41/500 [00:27<05:01,  1.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 40, Train Loss = 0.6194205981929127\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|█         | 51/500 [00:34<04:57,  1.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 50, Train Loss = 0.609858958160176\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|█▏        | 61/500 [00:40<04:53,  1.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 60, Train Loss = 0.5962320937484992\n"],"name":"stdout"},{"output_type":"stream","text":[" 14%|█▍        | 71/500 [00:47<04:40,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 70, Train Loss = 0.581903767837605\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|█▌        | 81/500 [00:53<04:33,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 80, Train Loss = 0.5825113039693715\n"],"name":"stdout"},{"output_type":"stream","text":[" 18%|█▊        | 91/500 [01:00<04:29,  1.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 90, Train Loss = 0.5799023155327682\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|██        | 101/500 [01:06<04:25,  1.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 100, Train Loss = 0.5752248507325012\n"],"name":"stdout"},{"output_type":"stream","text":[" 22%|██▏       | 111/500 [01:13<04:14,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 110, Train Loss = 0.5690807047727946\n"],"name":"stdout"},{"output_type":"stream","text":[" 24%|██▍       | 121/500 [01:20<04:08,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 120, Train Loss = 0.5650300132341621\n"],"name":"stdout"},{"output_type":"stream","text":[" 26%|██▌       | 131/500 [01:26<04:03,  1.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 130, Train Loss = 0.5591579775773842\n"],"name":"stdout"},{"output_type":"stream","text":[" 28%|██▊       | 141/500 [01:33<03:55,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 140, Train Loss = 0.5557717452657983\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|███       | 151/500 [01:39<03:48,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 150, Train Loss = 0.5534572279611171\n"],"name":"stdout"},{"output_type":"stream","text":[" 32%|███▏      | 161/500 [01:46<03:41,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 160, Train Loss = 0.5498977668166901\n"],"name":"stdout"},{"output_type":"stream","text":[" 34%|███▍      | 171/500 [01:52<03:34,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 170, Train Loss = 0.5477551162591454\n"],"name":"stdout"},{"output_type":"stream","text":[" 36%|███▌      | 181/500 [01:59<03:28,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 180, Train Loss = 0.5455635588472061\n"],"name":"stdout"},{"output_type":"stream","text":[" 38%|███▊      | 191/500 [02:05<03:23,  1.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 190, Train Loss = 0.541462921971426\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|████      | 201/500 [02:12<03:15,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 200, Train Loss = 0.5405542923146812\n"],"name":"stdout"},{"output_type":"stream","text":[" 42%|████▏     | 211/500 [02:19<03:11,  1.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 210, Train Loss = 0.5376183677341135\n"],"name":"stdout"},{"output_type":"stream","text":[" 44%|████▍     | 221/500 [02:25<03:03,  1.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 220, Train Loss = 0.5361383577547462\n"],"name":"stdout"},{"output_type":"stream","text":[" 46%|████▌     | 231/500 [02:32<02:58,  1.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 230, Train Loss = 0.5325822623777183\n"],"name":"stdout"},{"output_type":"stream","text":[" 48%|████▊     | 241/500 [02:38<02:52,  1.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 240, Train Loss = 0.5295129133952604\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|█████     | 251/500 [02:45<02:44,  1.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 250, Train Loss = 0.5263562492165432\n"],"name":"stdout"},{"output_type":"stream","text":[" 52%|█████▏    | 261/500 [02:51<02:36,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 260, Train Loss = 0.5235731767283546\n"],"name":"stdout"},{"output_type":"stream","text":[" 54%|█████▍    | 271/500 [02:58<02:28,  1.54it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 270, Train Loss = 0.5212473877021747\n"],"name":"stdout"},{"output_type":"stream","text":[" 56%|█████▌    | 281/500 [03:05<02:22,  1.54it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 280, Train Loss = 0.5189556102947832\n"],"name":"stdout"},{"output_type":"stream","text":[" 58%|█████▊    | 291/500 [03:11<02:16,  1.54it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 290, Train Loss = 0.5171980176799486\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|██████    | 301/500 [03:18<02:10,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 300, Train Loss = 0.515544342143195\n"],"name":"stdout"},{"output_type":"stream","text":[" 62%|██████▏   | 311/500 [03:24<02:04,  1.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 310, Train Loss = 0.5143679643942228\n"],"name":"stdout"},{"output_type":"stream","text":[" 64%|██████▍   | 321/500 [03:31<01:57,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 320, Train Loss = 0.5127807017241683\n"],"name":"stdout"},{"output_type":"stream","text":[" 66%|██████▌   | 331/500 [03:37<01:51,  1.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 330, Train Loss = 0.5112255546081462\n"],"name":"stdout"},{"output_type":"stream","text":[" 68%|██████▊   | 341/500 [03:44<01:44,  1.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 340, Train Loss = 0.5110085872261405\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|███████   | 351/500 [03:50<01:36,  1.54it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 350, Train Loss = 0.5104842759095706\n"],"name":"stdout"},{"output_type":"stream","text":[" 72%|███████▏  | 361/500 [03:57<01:30,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 360, Train Loss = 0.5093997088660824\n"],"name":"stdout"},{"output_type":"stream","text":[" 74%|███████▍  | 371/500 [04:03<01:24,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 370, Train Loss = 0.5082359979898139\n"],"name":"stdout"},{"output_type":"stream","text":[" 76%|███████▌  | 381/500 [04:10<01:18,  1.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 380, Train Loss = 0.5064343977475104\n"],"name":"stdout"},{"output_type":"stream","text":[" 78%|███████▊  | 391/500 [04:17<01:11,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 390, Train Loss = 0.504951516838025\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|████████  | 401/500 [04:23<01:05,  1.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 400, Train Loss = 0.5049975887498356\n"],"name":"stdout"},{"output_type":"stream","text":[" 82%|████████▏ | 411/500 [04:30<00:57,  1.54it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 410, Train Loss = 0.5051363802304233\n"],"name":"stdout"},{"output_type":"stream","text":[" 84%|████████▍ | 421/500 [04:36<00:51,  1.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 420, Train Loss = 0.5045444642563047\n"],"name":"stdout"},{"output_type":"stream","text":[" 86%|████████▌ | 431/500 [04:43<00:45,  1.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 430, Train Loss = 0.5044720318782081\n"],"name":"stdout"},{"output_type":"stream","text":[" 88%|████████▊ | 441/500 [04:49<00:38,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 440, Train Loss = 0.5055789061549569\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|█████████ | 451/500 [04:56<00:32,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 450, Train Loss = 0.5048433252158028\n"],"name":"stdout"},{"output_type":"stream","text":[" 92%|█████████▏| 461/500 [05:02<00:25,  1.55it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 460, Train Loss = 0.5034671441981177\n"],"name":"stdout"},{"output_type":"stream","text":[" 94%|█████████▍| 471/500 [05:09<00:18,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 470, Train Loss = 0.5029557168863381\n"],"name":"stdout"},{"output_type":"stream","text":[" 96%|█████████▌| 481/500 [05:15<00:12,  1.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 480, Train Loss = 0.5021342729952132\n"],"name":"stdout"},{"output_type":"stream","text":[" 98%|█████████▊| 491/500 [05:22<00:05,  1.54it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch = 0, Step = 490, Train Loss = 0.5007279759876111\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [05:28<00:00,  1.52it/s]\n"],"name":"stderr"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-f741168a464c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Call Train/Val Loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Begin Training!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-f84fd22315f4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs, model)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtrain_f1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_actual_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_predicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_actual_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_predicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_f1_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"]}]}]}