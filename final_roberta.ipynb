{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import RobertaModel, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup, RobertaConfig\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from dataset_loader import COVID19TweetDataset\n",
    "from baseline_classifier import BaselineClassifierLinear\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# TODO: Add tensorboard logging \n",
    "writer = SummaryWriter()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using Device: {}\".format(device))\n",
    "# Creating dataset\n",
    "DATA_DIR = './data'\n",
    "dataset_path = os.path.join(DATA_DIR, 'tweets_dataset.tsv')\n",
    "tweets_data_orig = pd.read_csv(dataset_path, sep='\\t')\n",
    "tweets_data_orig.loc[tweets_data_orig['expert'] == 'none_of_the_above', 'expert'] = 0\n",
    "tweets_data_orig.loc[tweets_data_orig['expert'] != 0, 'expert'] = 1\n",
    "tweets_data_final = tweets_data_orig[['text.clean', 'expert', 'id']]\n",
    "# print(tweets_data_final)\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME = 'roberta-base'\n",
    "MAX_LEN = 400\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train/test sets\n",
    "train_set, test_set = train_test_split(tweets_data_final,\n",
    "                                       test_size=0.1,\n",
    "                                       random_state=RANDOM_SEED)\n",
    "\n",
    "val_set, test_set = train_test_split(test_set,\n",
    "                                       test_size=0.5,\n",
    "                                       random_state=RANDOM_SEED)\n",
    "\n",
    "\n",
    "def create_data_loader(data_set, tokenizer, max_len, batch_size):\n",
    "    temp_data_set = COVID19TweetDataset(data_set['text.clean'].to_numpy(), data_set['expert'].to_numpy(),\n",
    "                                    data_set['id'].to_numpy(), max_len, tokenizer)\n",
    "\n",
    "    return DataLoader(temp_data_set, batch_size=batch_size)\n",
    "\n",
    "# Creating data loaders\n",
    "data_loader = {\n",
    "                'train': create_data_loader(train_set, tokenizer, MAX_LEN, BATCH_SIZE),\n",
    "                'val': create_data_loader(val_set, tokenizer, MAX_LEN, BATCH_SIZE),\n",
    "                'test': create_data_loader(test_set, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-94333f15b955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                             num_training_steps=len(data_loader['train']) * NUM_EPOCHS)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.088\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda2/envs/nlu/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n\u001b[1;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise AssertionError(\n",
      "\u001b[0;32m~/opt/miniconda2/envs/nlu/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Initializing model\n",
    "roberta_config = RobertaConfig.from_pretrained(PRE_TRAINED_MODEL_NAME, output_hidden_states=True)\n",
    "roberta_model = RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME, config=roberta_config)\n",
    "\n",
    "model = BaselineClassifierLinear(2, roberta_model)\n",
    "model = model.to(device)\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(data_loader['train']) * NUM_EPOCHS)\n",
    "\n",
    "class_weights = torch.FloatTensor([1.0, 2.088]).cuda()\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop\n",
    "def train(num_epochs, model):\n",
    "    history = []\n",
    "    best_val_f1 = float('-inf')\n",
    "    label_history = []\n",
    "    tensorboard_time_train = 0\n",
    "    tensorboard_time_val = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss_arr = []\n",
    "        train_predicted_labels = []\n",
    "        train_actual_labels = []\n",
    "        train_tweet_ids = []\n",
    "\n",
    "        for step, batch in enumerate(tqdm(data_loader['train'])):\n",
    "            tensorboard_time_train += 1\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            tweet_ids = batch['tweet_ids']\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_actual_labels += list(labels.detach().cpu().view(-1).numpy())\n",
    "            train_predicted_labels += list(predictions.detach().cpu().view(-1).numpy())\n",
    "            train_tweet_ids += tweet_ids\n",
    "            train_loss_arr.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            if step % 10 == 0:\n",
    "                print(f'Train Epoch = {epoch}, Step = {step}, Train Loss = {np.mean(train_loss_arr)}')\n",
    "            \n",
    "            writer.add_scalar('train_loss', np.mean(train_loss_arr), tensorboard_time_train)\n",
    "\n",
    "        train_f1_score = f1_score(np.array(train_actual_labels), np.array(train_predicted_labels))\n",
    "        train_acc = np.sum(np.array(train_actual_labels) == np.array(train_predicted_labels)) / len(train_set)\n",
    "        writer.add_scalar('train_f1_score', train_f1_score, epoch)\n",
    "\n",
    "        # Validation \n",
    "        model.eval()\n",
    "        val_loss_arr = []\n",
    "        val_predicted_labels = []\n",
    "        val_actual_labels = []\n",
    "        val_tweet_ids = []\n",
    "        with torch.no_grad():\n",
    "            for step, batch in enumerate(tqdm(data_loader['val'])):\n",
    "                tensorboard_time_val += 1\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                tweet_ids = batch['tweet_ids']\n",
    "\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                _, predictions = torch.max(outputs, dim=1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_actual_labels += list(labels.detach().cpu().view(-1).numpy())\n",
    "                val_predicted_labels += list(predictions.detach().cpu().view(-1).numpy())\n",
    "                val_tweet_ids += tweet_ids\n",
    "\n",
    "                val_loss_arr.append(loss.item())\n",
    "                if step % 10 == 0:\n",
    "                    print(f'Val Epoch = {epoch}, Step = {step}, Val Loss = {np.mean(val_loss_arr)}')\n",
    "                \n",
    "                writer.add_scalar('val_loss', np.mean(val_loss_arr), tensorboard_time_val)\n",
    "\n",
    "            val_f1_score = f1_score(np.array(val_actual_labels), np.array(val_predicted_labels))\n",
    "            val_acc = np.sum(np.array(val_actual_labels) == np.array(val_predicted_labels)) / len(val_set)\n",
    "            writer.add_scalar('val_f1_score', val_f1_score, epoch)\n",
    "        \n",
    "        # If we get better validation f1, save the labels/tweet ids for error analysis\n",
    "        if val_f1_score > best_val_f1:\n",
    "            best_val_f1 = val_f1_score\n",
    "            np.save(os.path.join(DATA_DIR, 'label_history.npy'), list(zip(val_actual_labels, \n",
    "                                                            val_predicted_labels, val_tweet_ids)))\n",
    "            save(model, epoch, optimizer, np.mean(val_loss_arr), model_prefix='roberta_linear_baseline_model_weighted_loss')\n",
    "        \n",
    "        print(f'Epoch {epoch}')\n",
    "        print('-' * 20)\n",
    "        print(f'Train Loss = {np.mean(train_loss_arr)}, F-1 Score = {train_f1_score}, Acc = {train_acc}')\n",
    "        print(f'Val Loss = {np.mean(val_loss_arr)}, F-1 Score = {val_f1_score}, Acc = {val_acc}')\n",
    "\n",
    "        # Save history\n",
    "        history.append([np.mean(train_loss_arr), np.mean(val_loss_arr), train_f1_score, val_f1_score])\n",
    "        np.save(os.path.join(DATA_DIR, 'history.npy'), history)\n",
    "\n",
    "\n",
    "def save(model, epoch, optimizer, loss, model_prefix='model_', root='/home/groups/kpohl/cs224u_models/.model'):\n",
    "    path = Path(root) / (model_prefix + '.ep%d' % epoch)\n",
    "    if not path.parent.exists():\n",
    "        path.parent.mkdir()\n",
    "\n",
    "    torch.save({'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(), 'loss': loss}, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Train/Val Loop\n",
    "print(\"Begin Training!\")\n",
    "train(NUM_EPOCHS, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_config = RobertaConfig.from_pretrained(PRE_TRAINED_MODEL_NAME, output_hidden_states=True)\n",
    "roberta_model = RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME, config=roberta_config)\n",
    "\n",
    "model = BaselineClassifierLinear(2, roberta_model)\n",
    "model = model.to(device)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "tweet = \"Hello, my dog is cute\"\n",
    "\n",
    "encoding = tokenizer.encode_plus(tweet, \n",
    "                                return_token_type_ids=False,\n",
    "                                pad_to_max_length=True,\n",
    "                                return_attention_mask=True,\n",
    "                                return_tensors='pt')  # Batch size 1\n",
    "\n",
    "outputs = roberta_model(encoding['input_ids'], attention_mask = encoding['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "print(outputs[2][12].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.cat(outputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 512, 768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
